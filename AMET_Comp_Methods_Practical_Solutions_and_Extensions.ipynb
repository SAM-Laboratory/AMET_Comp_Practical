{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "91cdc346",
      "metadata": {
        "id": "91cdc346"
      },
      "source": [
        "# Machine Learning Interatomic Potentials for Li-ion Diffusion in Batteries\n",
        "\n",
        "**AMET Computational Methods for Energy Materials Practical**\n",
        "\n",
        "---\n",
        "\n",
        "In this practical, we will work through the full pipeline of training machine-learned interatomic potentials (MLIPs) on Density Functional Theory (DFT) data, to then run fast molecular dynamics (MD) simulations to study ion transport in a solid-state electrolyte:\n",
        "\n",
        "1. **Explore** a dataset of DFT calculations for a lithium thiophosphate (Li-P-S) system\n",
        "2. **Train** a MLIP on the DFT data, and **validate** its accuracy\n",
        "3. **Run** molecular dynamics (MD) simulations with the trained ML potential\n",
        "4. **Extract** the Li-ion diffusion coefficient from the MD trajectories\n",
        "5. **Determine** the activation energy for Li-ion diffusion, via the Arrhenius relation\n",
        "\n",
        "### Why does this matter?\n",
        "\n",
        "Solid-state electrolytes are of great interest for next-generation lithium batteries with no liquid electrolyte components, offering improved safety (no more YouTube clips of Tesla batteries catching fire) and energy density.\n",
        "\n",
        "Understanding Li-ion transport at the atomic scale requires long molecular dynamics simulations that are often too expensive with DFT (AIMD) alone. MLIPs bridge this gap: we train a ML model on a relatively small set of DFT data, which we can afford to compute, then use this ML potential to run simulations orders of magnitude faster — at near-DFT accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mhBqQa8i7s30",
      "metadata": {
        "id": "mhBqQa8i7s30"
      },
      "source": [
        "**Note:**\n",
        "\n",
        "In this practical there are a number of technical and discussion/conceptual questions. It is recommended that you record answers as you go, and download the completed notebook at the end of the practical session, to use as a resource for reference with the practical report and follow-on task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9af7c83",
      "metadata": {
        "id": "f9af7c83"
      },
      "source": [
        "## Setup and Installation\n",
        "\n",
        "First, let's install the required packages. This practical uses:\n",
        "- **[MACE](https://github.com/ACEsuit/mace)**: A state-of-the-art equivariant MLIP architecture\n",
        "- **[ASE](https://wiki.fysik.dtu.dk/ase/)**: The Atomic Simulation Environment for structure manipulation and MD\n",
        "- Standard scientific Python: `numpy`, `matplotlib`, `scipy`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd516c1c",
      "metadata": {
        "id": "bd516c1c"
      },
      "source": [
        "As discussed in our lectures, GPUs can be much faster for Molecular Dynamics and ML training/deployment. We can use GPUs in Colab by following these instructions:\n",
        "\n",
        "**To activate the GPU, click on the down arrow in the top right of the editor, click on \"Change runtime type\" and select \"T4 GPU\" from the menu Hardware accelerator and save.\n",
        "Then click on \"Connect\". If this doesn't work, change all \"cuda\" instances in the notebook to \"cpu\" (and use the slower CPU option instead).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e2c90a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# this automatically downloads our data, so we don't need to manually download and upload\n",
        "# as we did in the practical session:\n",
        "!git clone https://github.com/SAM-Laboratory/AMET_Comp_Practical\n",
        "%cd AMET_Comp_Practical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51dcff69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51dcff69",
        "outputId": "880f7a30-8dfd-460f-b57b-a36982f847fd"
      },
      "outputs": [],
      "source": [
        "# Install required packages:\n",
        "!pip install mace-torch ase matplotlib numpy scipy pymatviz pymatgen\n",
        "!pip install cuequivariance_torch  # this speeds up our model training (accelerated tensor products)\n",
        "# Make sure Runtime -> Change runtime type -> GPU is selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e37a73",
      "metadata": {
        "id": "e7e37a73"
      },
      "outputs": [],
      "source": [
        "# import standard scientific Python packages; numpy, matplotlib:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\")  # ignore irrelevant warnings for this practical"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f418d865",
      "metadata": {
        "id": "f418d865"
      },
      "source": [
        "---\n",
        "# Part 1: Exploring the DFT Training Data\n",
        "\n",
        "Before training any model, we need to understand our reference data. We have a dataset of DFT calculations for a lithium thiophosphate system stored in `LiPS.xyz.gz`.\n",
        "\n",
        "**Key questions to answer:**\n",
        "- What are the chemical compositions present in the dataset?\n",
        "- How large are the simulation cells?\n",
        "- What is the range of energies and forces?\n",
        "- What do the structures look like?\n",
        "- How many configurations are there? (i.e. how much data do we have?)\n",
        "- How many atoms of each _element_ do we have in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XrZwOKYztyu1",
      "metadata": {
        "id": "XrZwOKYztyu1"
      },
      "outputs": [],
      "source": [
        "!gzip -d LiPS.xyz.gz  # decompress the data file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed50d613",
      "metadata": {
        "id": "ed50d613"
      },
      "source": [
        "Here the data is stored in XYZ format (.xyz). Let's quickly look at the first few lines of the file to show what this format looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff982f0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff982f0e",
        "outputId": "68fc812c-a2cb-4492-c155-8325324a772e"
      },
      "outputs": [],
      "source": [
        "!head LiPS.xyz  # using \"!<command...>\" runs a shell command in Jupyter notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c2fcca3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c2fcca3",
        "outputId": "2f637905-4ed5-430c-b1df-fd9ca7856842"
      },
      "outputs": [],
      "source": [
        "# show the lines 80-90:\n",
        "!head -n 90 LiPS.xyz | tail -n 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55678611",
      "metadata": {
        "id": "55678611"
      },
      "source": [
        "We can see that the data file contains information about the number of atoms, the lattice parameters, the energy of the cell, then lines with the atomic species, positions, and forces (in x/y/z axes), for each calculation in the dataset. We typically refer to each set of atomic positions, forces, and corresponding energy as a 'frame' or 'configuration'.\n",
        "\n",
        "We can use the [`ase.io.read`](https://ase-lib.org/ase/io/io.html) function to load the data into a list of ASE `Atoms` objects, which are Python classes that store information about a given simulation cell (structure, energy, forces, etc.).\n",
        "\n",
        "Let's load the data and run some simple analyses:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2690fc4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2690fc4c",
        "outputId": "cf7ca242-4720-4587-94c3-d75cbf225ede"
      },
      "outputs": [],
      "source": [
        "# Load the dataset, which is stored in XYZ format (.xyz)\n",
        "# Each frame contains: atomic positions, forces, total energy, and the simulation cell\n",
        "from ase.io import read\n",
        "\n",
        "print(\"Loading DFT dataset...\")\n",
        "dataset = read(\"LiPS.xyz\", index=\":\")  # read all frames in the dataset\n",
        "print(f\"Loaded {len(dataset)} configurations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e93e3fe",
      "metadata": {
        "id": "0e93e3fe"
      },
      "source": [
        "### 1.1 Chemical Composition\n",
        "\n",
        "Let's determine what elements are present and in what proportions. This will tell us what\n",
        "materials/compositions we're working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92b0607c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92b0607c",
        "outputId": "39cab3f1-721c-42e5-923a-c19bcbbb1dac"
      },
      "outputs": [],
      "source": [
        "# dataset is a list of Atoms objects\n",
        "print(type(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e7aa6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89e7aa6f",
        "outputId": "3fb4b9a2-12e5-49e6-fa8a-46790c032470"
      },
      "outputs": [],
      "source": [
        "# let's look at just the first configuration in the dataset (list) to start:\n",
        "first_frame = dataset[0]\n",
        "print(first_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c001a216",
      "metadata": {
        "id": "c001a216"
      },
      "source": [
        "We can see that just printing the `Atoms` object shows us information about the configuration, including the chemical species present, the cell parameters, etc.\n",
        "\n",
        "For instance here we see that the configuration has a chemical formula of Li27P12S44. Can this formula be reduced?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b247819",
      "metadata": {
        "id": "6b247819"
      },
      "source": [
        "If we haven't used ASE before, how can we figure out what information is stored in the `Atoms` object, and how to access it?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ae4a484",
      "metadata": {
        "id": "4ae4a484"
      },
      "source": [
        "1. Documentation – We can find online documentation for ASE, and the `Atoms` class. See for example the [ASE Atoms class documentation](https://ase-lib.org/ase/atoms.html).\n",
        "    \n",
        "    For reasonably popular codes, generative AI tools like ChatGPT can also give useful information, but as always we should be suspicious of the accuracy of the answers! Ask a genAI tool what the `Atoms` class is, and what information it contains."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "844954a8",
      "metadata": {
        "id": "844954a8"
      },
      "source": [
        "From looking at the documentation, how can we get information about the chemical composition of the configuration?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11a2528b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11a2528b",
        "outputId": "45d921cb-ef35-44d3-8853-e43c1f46b5b1"
      },
      "outputs": [],
      "source": [
        "first_frame.get_chemical_symbols()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae50769",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7ae50769",
        "outputId": "34d6556d-d23f-446e-f3dc-4002bfcca857"
      },
      "outputs": [],
      "source": [
        "first_frame.get_chemical_formula()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97fd1b70",
      "metadata": {
        "id": "97fd1b70"
      },
      "source": [
        "2. Docstrings – We can access the 'docstring' (short descriptions of the object/functions), using the `help` function, by looking in the Python code itself, using `<object>?` in a Jupyter notebook cell, or by other means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0548b09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0548b09",
        "outputId": "811bd73c-7e2e-4f00-a4eb-902b35b25b11"
      },
      "outputs": [],
      "source": [
        "help(first_frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ddfd345",
      "metadata": {
        "id": "5ddfd345"
      },
      "outputs": [],
      "source": [
        "first_frame?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "046e4e47",
      "metadata": {
        "id": "046e4e47"
      },
      "source": [
        "\n",
        "3. `dir()` – We can use the `dir()` function to get a list of all the attributes (information) and methods (functions) of an object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "161b3492",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "161b3492",
        "outputId": "e6647dd5-f32e-4f48-9fc2-55bf00de4183"
      },
      "outputs": [],
      "source": [
        "dir(first_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c29a7fa",
      "metadata": {
        "id": "7c29a7fa"
      },
      "source": [
        "Ok here it looks like using the `get_chemical_formula()` function will give us the information we need. We could also use `get_chemical_symbols()` to get the list of elements present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L5vuCQ824zZm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "L5vuCQ824zZm",
        "outputId": "0aba9980-a8b4-4c87-9231-b1acea24e3e3"
      },
      "outputs": [],
      "source": [
        "first_frame.get_chemical_formula()  # same formula, not reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SvT5Bd4q44Cb",
      "metadata": {
        "id": "SvT5Bd4q44Cb"
      },
      "outputs": [],
      "source": [
        "# just for context, we can also use the pymatgen package (pymatgen.org) to get the reduced chemical formula:\n",
        "from pymatgen.core.composition import Composition\n",
        "\n",
        "comp = Composition(\"Li27P12S44\")\n",
        "print(comp)\n",
        "comp.get_reduced_formula_and_factor()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "081adf50",
      "metadata": {
        "id": "081adf50"
      },
      "source": [
        "Let's check if all the compositions are the same, or if there are different compositions present in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c21b6d7",
      "metadata": {
        "id": "3c21b6d7"
      },
      "outputs": [],
      "source": [
        "# let's first get a list of all the chemical formulae present in the dataset:\n",
        "list_of_formulas = []\n",
        "for frame in dataset:\n",
        "    list_of_formulas.append(frame.get_chemical_formula())\n",
        "\n",
        "# alternatively, more concisely, we could use a Python 'list comprehension':\n",
        "# list_of_formulas = [frame.get_chemical_formula() for frame in dataset]\n",
        "print(list_of_formulas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5dc22b",
      "metadata": {
        "id": "4d5dc22b"
      },
      "outputs": [],
      "source": [
        "# this is a very long list; how can we determine the unique formulae?\n",
        "# we can use a Python set to get the unique formulae:\n",
        "unique_formulas = list(set(list_of_formulas))\n",
        "print(unique_formulas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9519d031",
      "metadata": {
        "id": "9519d031"
      },
      "outputs": [],
      "source": [
        "# Advanced:\n",
        "# we could also use a Python dictionary to count the number of times each formula appears:\n",
        "formula_counts = {}\n",
        "for formula in list_of_formulas:\n",
        "    if formula in formula_counts:\n",
        "        formula_counts[formula] += 1\n",
        "    else:\n",
        "        formula_counts[formula] = 1\n",
        "\n",
        "# or numpy:\n",
        "# formula_counts = np.unique(list_of_formulas, return_counts=True)\n",
        "print(formula_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47582876",
      "metadata": {
        "id": "47582876"
      },
      "source": [
        "So here we are dealing with a dataset of all Li27P12S44 configurations. This is one of the Li-P-S class of solid-state electrolytes; specifically a Li-deficient derivative of Li7P3S11 (which is known as \"LPS\"). Some relevant papers about LiPS:\n",
        "- https://pubs.rsc.org/en/content/articlelanding/2014/ee/c3ee41655k\n",
        "- https://pubs.acs.org/doi/10.1021/acs.chemmater.6b02163\n",
        "\n",
        "4 formula units of Li7P3S11 gives Li28P12S44, while we have Li27P12S44 – so what type of 'defect' do we have in our system?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "787b3ae2",
      "metadata": {
        "id": "787b3ae2"
      },
      "source": [
        "### 1.2 Simulation Cell Sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b2d4f16",
      "metadata": {
        "id": "7b2d4f16"
      },
      "source": [
        "How many atoms in the frames?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a869f964",
      "metadata": {
        "id": "a869f964"
      },
      "outputs": [],
      "source": [
        "natoms = [len(frame) for frame in dataset]\n",
        "print(set(natoms))  # many ways of doing this; all the same 83 atoms per frame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e9d1dae",
      "metadata": {
        "id": "0e9d1dae"
      },
      "source": [
        "What about the cell volumes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52670552",
      "metadata": {
        "id": "52670552"
      },
      "outputs": [],
      "source": [
        "volumes = [frame.get_volume() for frame in dataset]\n",
        "print(set(volumes))  # many ways of doing this; all the same (fixed) volume"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "733e0374",
      "metadata": {
        "id": "733e0374"
      },
      "source": [
        "What cell lengths?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3611eecb",
      "metadata": {
        "id": "3611eecb"
      },
      "outputs": [],
      "source": [
        "print(first_frame.cell.lengths())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dcf98ee",
      "metadata": {
        "id": "4dcf98ee"
      },
      "source": [
        "### 1.3 Energy and Force Distributions\n",
        "\n",
        "The energy and force distributions give us an indication about the range of configurations sampled by the DFT calculations – or in other words, how much of the potential energy surface (PES) we have explored.\n",
        "\n",
        "Wide energy/force distributions mean diverse training data (wide exploration), while narrow distributions mean only a narrow region of PES is sampled.\n",
        "\n",
        "Which is better for 'generalisability' (i.e. how well the model will perform on new structures/configurations)?\n",
        "\n",
        "Which is better for accuracy in the same region of the PES (if we just need the model to very accurately reproduce DFT for a specific region of the PES)?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e88164cd",
      "metadata": {
        "id": "e88164cd"
      },
      "source": [
        "How can we access the energy and forces from the `Atoms` object? (Tip: Use the instructions above on how to access information/functions of an object in Python!)\n",
        "\n",
        "Let's plot the distribution of these energies and forces. First we need to extract the energies and forces:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xkULbHBa7MP_",
      "metadata": {
        "id": "xkULbHBa7MP_"
      },
      "outputs": [],
      "source": [
        "# Extract energies and forces from all configurations\n",
        "# this code needs to be filled in:\n",
        "energies = ...  # array of shape (nframes,)\n",
        "energies_per_atom = ...  # array of shape (nframes,)\n",
        "forces = ... # likely to be array of shape (nframes, natoms, 3) with x/y/z components"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RMAmbtwT7RD6",
      "metadata": {
        "id": "RMAmbtwT7RD6"
      },
      "source": [
        "Given energies and forces arrays, this code plots the distributions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oaP2GZM86kr1",
      "metadata": {
        "id": "oaP2GZM86kr1"
      },
      "outputs": [],
      "source": [
        "# convert x/y/z force components to total force vector norm\n",
        "force_magnitudes = np.linalg.norm(forces, axis=-1)  # converts (nframes, natoms, 3) to array of shape (nframes, natoms)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Energy distribution\n",
        "axes[0].hist(energies, bins=60, color=\"steelblue\", edgecolor=\"white\", alpha=0.8)\n",
        "axes[0].set_xlabel(\"Energy (eV)\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "axes[0].set_title(\"Energy Distribution\")\n",
        "\n",
        "# Energy per atom distribution\n",
        "axes[1].hist(energies_per_atom, bins=60, color=\"mediumpurple\", edgecolor=\"white\", alpha=0.8)\n",
        "axes[1].set_xlabel(\"Energy per atom (eV)\")\n",
        "axes[1].set_ylabel(\"Count\")\n",
        "axes[1].set_title(\"Energy Distribution\")\n",
        "\n",
        "# Force magnitude distribution (sample for speed)\n",
        "sample_forces = force_magnitudes[::10].flatten()  # every 10th frame\n",
        "axes[2].hist(sample_forces, bins=80, color=\"coral\", edgecolor=\"white\", alpha=0.8, range=(0, 5))\n",
        "axes[2].set_xlabel(\"|F| (eV/Å)\")\n",
        "axes[2].set_ylabel(\"Count\")\n",
        "axes[2].set_title(\"Force Magnitude Distribution\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Energy range: {energies.min():.4f} to {energies.max():.4f} eV; spread: {energies.max() - energies.min():.4f} eV\")\n",
        "print(f\"Per-atom energy range: {energies_per_atom.min():.4f} to {energies_per_atom.max():.4f} eV/atom; spread: {energies_per_atom.max() - energies_per_atom.min():.4f} eV/atom\")\n",
        "print(f\"Mean |F|: {force_magnitudes.mean():.3f} eV/Å\")\n",
        "print(f\"Max |F|: {force_magnitudes.max():.3f} eV/Å\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "441c02ec",
      "metadata": {
        "id": "441c02ec"
      },
      "source": [
        "### 1.3 Visualising the Structure\n",
        "\n",
        "Let's look at what these structures actually look like. We can use the `plot_atoms` and `view` function from `ase.visualize` to visualise the structure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241d41c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "241d41c1",
        "outputId": "e791e4fe-d67e-4529-f0b3-9905be18a660"
      },
      "outputs": [],
      "source": [
        "from ase.visualize.plot import plot_atoms\n",
        "\n",
        "plot_atoms(first_frame, radii=0.8, rotation=\"10x,10y,0z\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2330df5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "f2330df5",
        "outputId": "d8b067a4-5bd3-4ee3-ff95-85d15dc4e1a8"
      },
      "outputs": [],
      "source": [
        "from ase.visualize import view\n",
        "\n",
        "view(first_frame, viewer='x3d')\n",
        "# this plot is interactive! you can drag and rotate the structure here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a3419c",
      "metadata": {
        "id": "09a3419c"
      },
      "source": [
        "A more advanced, interactive visualisation can be obtained using `pymatviz` (a recently developed package for visualising and analysing materials data – [LinkedIn post](https://www.linkedin.com/posts/janosh-riebesell_two-updates-to-share-one-personal-and-one-activity-7353429148192653312-3cc3?utm_source=share&utm_medium=member_desktop&rcm=ACoAABqLVRMBp4swyiCmc7OnE6Iy_7fIdPmF_wE)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e0c411",
      "metadata": {
        "id": "b0e0c411"
      },
      "outputs": [],
      "source": [
        "from pymatviz import widgets\n",
        "\n",
        "widgets.StructureWidget(first_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d547827c",
      "metadata": {
        "id": "d547827c"
      },
      "source": [
        "This widget has a lot of useful tools, including the ability to measure distances and angles, change view orientation, and more."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "771e39ed",
      "metadata": {
        "id": "771e39ed"
      },
      "source": [
        "We can also use the `TrajectoryWidget` to visualise a set of multiple configurations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1cbc18f",
      "metadata": {
        "id": "e1cbc18f"
      },
      "outputs": [],
      "source": [
        "widgets.TrajectoryWidget(dataset[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b92bdf37",
      "metadata": {
        "id": "b92bdf37"
      },
      "source": [
        "Here we can press the play button to iterate through the different structures (frames) in our dataset – hint: increase the frames per second to ~20 for a smoother animation.\n",
        "Looking at the data this way, we can learn a few things about the dataset:\n",
        "\n",
        "- What type of calculation(s) did this data come from? e.g. geometry relaxations, random snapshots of different configurations (e.g. from 'rattling'), ab-initio molecular dynamics, volume scaling, etc.\n",
        "\n",
        "- What can we guess about the simulation conditions? (Ensemble choice, temperature, etc...)\n",
        "\n",
        "- Which atoms seem to be the most mobile / easily displaced in this structure? Does this make sense? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a6a91b",
      "metadata": {
        "id": "f6a6a91b"
      },
      "source": [
        "The energy spread across the dataset is relatively narrow. Why is this? *(Hint: these are all configurations of the same material at similar conditions.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ee4a970",
      "metadata": {
        "id": "0ee4a970"
      },
      "source": [
        "---\n",
        "# Part 2: Training a MACE Model\n",
        "In this practical, we will fit and test a `MACE` model (Message Passing Neural Network), which is a highly accurate and efficient MLIP (Machine Learned Interatomic Potential). The training/testing techniques we show here, however, are broadly applicable to all MLIPs.\n",
        "\n",
        "You can independently learn about MACE by studying the [original method paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/4a36c3c51af11ed9f34615b81edb5bbc-Paper-Conference.pdf). MACE was developed by unifying the Atomic Cluster Expansion (ACE) approach with the Neural Equivariant Interatomic Potentials (NequIP). The mathematical formalism which unifies these methods is explained in the [accompaning paper](https://doi.org/10.48550/arXiv.2205.06643). Another [useful reference](https://doi.org/10.48550/arXiv.2305.14247) showcases the method's performance on published benchmark datasets. The [code implementation](https://github.com/ACEsuit/mace) is publically available and [here](https://mace-docs.readthedocs.io/en/latest/) you can find the documentation.\n",
        "\n",
        "## Learning Objectives for today:\n",
        "\n",
        "1. **Understanding the data**\n",
        "2. **Fitting and testing MACE models**\n",
        "3. **Running Molecular Dynamics**\n",
        "\n",
        "Here we have a high-level explanation of the important parameters in MACE. You can consult the [documentation](https://github.com/ACEsuit/mace) for additional parameters.\n",
        "\n",
        "- ##### <font color='red'>--num_interactions</font>: message-passing layers\n",
        "\n",
        "Controls the number of message-passing layers in our deep neural network model.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color='red'>--num_channels=32</font>\n",
        "\n",
        "Controls the width of our neural network layers.\n",
        "\n",
        "- ##### <font color='red'>--r_max</font>: the cutoff radius\n",
        "\n",
        "The radial cut-off applied to the local atomic environment in each layer. `r_max=3.0` means atoms separated by a distance of more than 3.0 A do not directly _communicate_. When the model has multiple message-passing layers, atoms further than 3.0 A can still _communicate_ through later messages if intermediate proxy atoms exist. The effective _receptive field_ of the model is `num_interactions x r_max` (i.e. number of layers times the per-layer radial cutoff).\n",
        "\n",
        "- ##### <font color='red'>--max_ell</font>: angular resolution\n",
        "\n",
        "The angular resolution describes how well the model can describe angles.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color='red'>--max_L=1</font>\n",
        "\n",
        "Controls the level of 'equivariance' of the model; L=0 is invariant, L=1 is equivariant, L>=2 are higher levels of equivariance.\n",
        "\n",
        "<font color='blue'>**In general, the `accuracy` of the model can be improved by using more layers, more channels or higher equivariances. This will result in more parameters and `slower` models, as discussed in lectures.**</font>\n",
        "\n",
        "\n",
        "Let's train our first model!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac00934e",
      "metadata": {
        "id": "ac00934e"
      },
      "source": [
        "### 2.1 Preparing the Data\n",
        "\n",
        "We split the dataset into training, validation, and test sets. Typically the ML model is trained on the training set, constantly evaluated on the validation set, and then tested/evaluated on the test set at the end of training.\n",
        "\n",
        "The validation set is used during training to monitor for overfitting (typically when training error is decreasing, but validation error is increasing).\n",
        "The test set provides an independent measure of accuracy *after* training is complete.\n",
        "\n",
        "As discussed above, this data comes from ab-initio molecular dynamics simulations, one of the common data generation approaches for MLIPs. However one drawback of this approach is that the data is highly-correlated, with each successive step in the MD simulation being quite similar to the previous step. This increases the redundancy in the data, and so often we sub-sample the full MD trajectory to reduce the amount of data we need to train on while retaining most of the useful information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9894b5a",
      "metadata": {
        "id": "c9894b5a"
      },
      "source": [
        "Here we'll subsample to retain 10% of the MD trajectory data, and then use a random split of this subsampled data to generate the training, validation, and test sets, which we can do using the `train_test_split` function from `sklearn` (scikit-learn). Let's use a 80:10:10 split for the training, validation, and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f39c0d45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f39c0d45",
        "outputId": "a4813b03-3656-4755-9534-70da775b0c5d"
      },
      "outputs": [],
      "source": [
        "from ase.io import write\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# first, subsample 10% of the dataset\n",
        "subsampled_dataset = dataset[::10]  # this takes every 10th frame in the dataset\n",
        "\n",
        "# First split off train from test/val; with 80/20 split\n",
        "train_set, test_val_set = train_test_split(subsampled_dataset, train_size=0.8, test_size=0.2)\n",
        "\n",
        "# split test/val into val and test; with 50/50 split (corresponding to 10/10 split overall)\n",
        "test_set, val_set = train_test_split(test_val_set, test_size=0.5, train_size=0.5)\n",
        "\n",
        "# Save split datasets to files for MLIP training\n",
        "write(\"LiPS_train.xyz\", train_set)\n",
        "write(\"LiPS_val.xyz\", val_set)\n",
        "write(\"LiPS_test.xyz\", test_set)\n",
        "\n",
        "print(f\"Training set:   {len(train_set)} configurations\")\n",
        "print(f\"Validation set: {len(val_set)} configurations\")\n",
        "print(f\"Test set:       {len(test_set)} configurations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "831632f1",
      "metadata": {
        "id": "831632f1"
      },
      "source": [
        "### 2.2 Training the Model\n",
        "\n",
        "We write a YAML configuration file and call the MACE training script.\n",
        "With this initial setup, training should converge in roughly 10 minutes on a GPU.\n",
        "\n",
        "While the model trains, watch the output — you should see the energy and force errors decreasing with each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa600a0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa600a0a",
        "outputId": "0824e12d-4cb0-40a5-c6f1-b08c11e5305e"
      },
      "outputs": [],
      "source": [
        "# Write the MACE configuration file:\n",
        "%%writefile mace_config.yml\n",
        "# model hyperparameters\n",
        "model: \"MACE\"\n",
        "num_interactions: 2\n",
        "num_channels: 32\n",
        "r_max: 4.0\n",
        "max_ell: 1\n",
        "max_L: 0\n",
        "\n",
        "# training settings\n",
        "name: \"LiPS_MACE\"  # name for our model\n",
        "train_file: \"LiPS_train.xyz\"\n",
        "valid_file: \"LiPS_val.xyz\"\n",
        "test_file: \"LiPS_test.xyz\"\n",
        "device: cuda  # 'cuda' for GPU training, 'cpu' for CPU training\n",
        "batch_size: 30\n",
        "max_num_epochs: 50  # ~10 mins with current model, with GPU training\n",
        "default_dtype: float32\n",
        "E0s: average\n",
        "swa: True\n",
        "# default values are shown here: https://github.com/ACEsuit/mace/blob/main/mace/tools/arg_parser.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7314166e",
      "metadata": {
        "id": "7314166e"
      },
      "source": [
        "There are some additional settings we must give in our training configuration file:\n",
        "\n",
        "- ##### <font color='red'>--name</font>: the name of the model\n",
        "This name will be used to form file names (model, log, checkpoints, results), so choose a distinct name for each experiment.\n",
        "\n",
        "- ##### <font color='red'>--train/valid/test_file</font>: path to training/validation/testing data\n",
        "\n",
        "- ##### <font color='red'>--device</font> computing device to use\n",
        "Can be CPU (`cpu`) or GPU (`cuda`). Here we will use `cuda` since the GPU will be significantly faster than the CPU.\n",
        "\n",
        "- ##### <font color='red'>--batch_size</font> number of frames to evaluate in one 'batch' (i.e. model parameter update). This training strategy is called stochastic gradient descent because only a subset of the data (`batch_size`) is used to change the parameters at each update.\n",
        "\n",
        "- ##### <font color='red'>--max_num_epochs</font> maximum number of passes through the data ('epochs'). An _epoch_ is completed when the entire training data has been used once in updating the weights _batch_ by _batch_. \n",
        "\n",
        "Now we are ready to fit our first MACE model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8Fo4LrsZaMsJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fo4LrsZaMsJ",
        "outputId": "526fb744-8f80-46ef-af61-368f177890e4"
      },
      "outputs": [],
      "source": [
        "# Train the MACE model;\n",
        "# this command prints a lot of information and many warnings (which we can ignore)\n",
        "# here we have some code which runs the main MACE training command, and tries to minimise the warnings output:\n",
        "# we don't need to worry about what these individual function calls are doing; main thing to know is that it is\n",
        "# running MACE model training using the config file (`mace_config.yml`) that we specify\n",
        "import sys\n",
        "import logging\n",
        "from mace.cli.run_train import main as mace_run_train_main\n",
        "\n",
        "def train_mace(config_file_path):\n",
        "    \"\"\"Train a MACE model from a YAML config file.\"\"\"\n",
        "    logging.getLogger().handlers.clear()\n",
        "    sys.argv = [\"program\", \"--config\", config_file_path]\n",
        "    mace_run_train_main()\n",
        "\n",
        "print(\"Starting MACE training...\")\n",
        "train_mace(\"mace_config.yml\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6Sgkw1Zo-uy4",
      "metadata": {
        "id": "6Sgkw1Zo-uy4"
      },
      "source": [
        "Sometimes Colab times out and cuts access to files in this current 'runtime', so it is recommended to download the `LiPS_MACE_stagetwo_compiled.model` file to your local PC now; by clicking on the 'Files' tab on the left and downloading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a70676",
      "metadata": {
        "id": "21a70676"
      },
      "outputs": [],
      "source": [
        "# Cleanup operations;\n",
        "# this code just removes some checkpoint files since they may cause errors on retraining a model with the same name but a different architecture:\n",
        "import glob\n",
        "import os\n",
        "for file in glob.glob(\"checkpoints/*_run-*.model\"):\n",
        "    os.remove(file)\n",
        "for file in glob.glob(\"checkpoints/*.pt\"):\n",
        "    os.remove(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a2cb68",
      "metadata": {
        "id": "45a2cb68"
      },
      "source": [
        "We could tune the hyperparameters used to train the model to improve its accuracy. For now, we will proceed with the current parameters, but later we will revisit this."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57db0247",
      "metadata": {
        "id": "57db0247"
      },
      "source": [
        "### 2.3 Evaluating the Model\n",
        "\n",
        "A good MLIP should accurately reproduce the DFT energies and forces. We check this\n",
        "with **parity plots**: predicted vs. reference values. Points close to the diagonal\n",
        "line $y = x$ indicate good predictions.\n",
        "\n",
        "The key metrics are:\n",
        "- **Energy MAE** (mean absolute error): typically should be ~1–5 meV/atom for a good potential\n",
        "- **Force MAE**: typically should be <50 meV/Å for reliable MD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8db9b7c",
      "metadata": {
        "id": "d8db9b7c"
      },
      "source": [
        "To evaluate the model performance, we load the trained model, and use it to predict the energies and forces for our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bab3ac17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bab3ac17",
        "outputId": "5d19d047-3ef7-4c72-8c2c-03ef01482633"
      },
      "outputs": [],
      "source": [
        "from mace.calculators import MACECalculator\n",
        "\n",
        "# load our model using the MACECalculator class, which works with ASE:\n",
        "calc = MACECalculator(\n",
        "    model_paths=[\"LiPS_MACE_stagetwo_compiled.model\"],  # file path of trained model\n",
        "    device=\"cuda\",  # change to \"cpu\" if no CUDA GPU\n",
        "    default_dtype=\"float32\",\n",
        ")\n",
        "\n",
        "# Evaluate on our dataset:\n",
        "# let's create a dictionary to store the results for each dataset:\n",
        "dataset_evaluations = {}\n",
        "\n",
        "from tqdm import tqdm  # we can use this to show a progress bar\n",
        "\n",
        "for dataset_name in [\"train\", \"val\", \"test\"]:\n",
        "    data = read(f\"LiPS_{dataset_name}.xyz\", index=\":\")  # load the data\n",
        "\n",
        "    # we will store the results in lists:\n",
        "    dft_energies = []\n",
        "    dft_forces = []\n",
        "    mace_energies = []\n",
        "    mace_forces = []\n",
        "\n",
        "    for atoms in tqdm(data):  # iterate over the frames in the data\n",
        "        # first collect reference DFT energies and forces:\n",
        "        dft_energies.append(atoms.info[\"REF_energy\"] / len(atoms))  # energies per atom\n",
        "        dft_forces.append(atoms.arrays[\"REF_forces\"].flatten())  # forces per atom\n",
        "        # (we use flatten() to convert the 1x3 array of x/y/z forces to a 1D array, that we can add to lists)\n",
        "\n",
        "        # then predict energies and forces using our trained model:\n",
        "        # to do this with ASE, we attach our trained model Calculator to the atoms\n",
        "        # object (atoms.calc), which is then used when we call the\n",
        "        # get_potential_energy() or get_forces() methods:\n",
        "        atoms.calc = calc  # set the calculator to our trained model\n",
        "        mace_energies.append(atoms.get_potential_energy() / len(atoms))  # energies per atom\n",
        "        mace_forces.append(atoms.get_forces().flatten())  # forces per atom\n",
        "\n",
        "    # convert the lists to numpy arrays for easier processing, and add to dict:\n",
        "    dataset_evaluations[dataset_name] = {\n",
        "        \"dft_energies\": np.array(dft_energies),\n",
        "        \"dft_forces\": np.array(dft_forces),\n",
        "        \"mace_energies\": np.array(mace_energies),\n",
        "        \"mace_forces\": np.array(mace_forces),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70520c55",
      "metadata": {
        "id": "70520c55"
      },
      "source": [
        "To analyse the model performance, we can generate 'parity plots' of the predicted vs. reference energies and forces:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dafebaa1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dafebaa1",
        "outputId": "392c875c-8d9b-4cc0-b046-447f1a9f4e68"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3, 2, figsize=(10, 13))\n",
        "\n",
        "for i, dataset_name in enumerate([\"train\", \"val\", \"test\"]):\n",
        "    data = dataset_evaluations[dataset_name]\n",
        "    dft_e = data[\"dft_energies\"]\n",
        "    ml_e = data[\"mace_energies\"]\n",
        "    dft_f = data[\"dft_forces\"]\n",
        "    ml_f = data[\"mace_forces\"]\n",
        "\n",
        "    # Energy metrics (meV/atom)\n",
        "    e_mae = np.mean(np.abs(dft_e - ml_e)) * 1000\n",
        "    e_rmse = np.sqrt(np.mean((dft_e - ml_e) ** 2)) * 1000\n",
        "\n",
        "    # Force metrics (meV/Å)\n",
        "    f_mae = np.mean(np.abs(dft_f - ml_f)) * 1000\n",
        "    f_rmse = np.sqrt(np.mean((dft_f - ml_f) ** 2)) * 1000\n",
        "\n",
        "    # Energy parity plot\n",
        "    ax_e = axes[i, 0]\n",
        "    ax_e.scatter(dft_e, ml_e, s=8, alpha=0.5, color=\"steelblue\",\n",
        "                 label=f\"MAE = {e_mae:.1f} meV/atom\\nRMSE = {e_rmse:.1f} meV/atom\")\n",
        "    lims = [min(dft_e.min(), ml_e.min()), max(dft_e.max(), ml_e.max())]\n",
        "    ax_e.plot(lims, lims, \"k--\", linewidth=1)\n",
        "    ax_e.set_xlabel(\"DFT energy (eV/atom)\")\n",
        "    ax_e.set_ylabel(\"MACE energy (eV/atom)\")\n",
        "    ax_e.set_title(f\"{dataset_name} — Energy\")\n",
        "    ax_e.set_aspect(\"equal\")\n",
        "    ax_e.legend(fontsize=8, loc=\"upper left\")\n",
        "\n",
        "    # Force parity plot\n",
        "    ax_f = axes[i, 1]\n",
        "    ax_f.scatter(dft_f, ml_f, s=1, alpha=0.1, color=\"coral\",\n",
        "                 label=f\"MAE = {f_mae:.1f} meV/Å\\nRMSE = {f_rmse:.1f} meV/Å\")\n",
        "    flims = [dft_f.min(), dft_f.max()]\n",
        "    ax_f.plot(flims, flims, \"k--\", linewidth=1)\n",
        "    ax_f.set_xlabel(\"DFT force component (eV/Å)\")\n",
        "    ax_f.set_ylabel(\"MACE force component (eV/Å)\")\n",
        "    ax_f.set_title(f\"{dataset_name} — Forces\")\n",
        "    ax_f.set_aspect(\"equal\")\n",
        "    ax_f.legend(fontsize=8, loc=\"upper left\", markerscale=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e3c3321",
      "metadata": {
        "id": "6e3c3321"
      },
      "source": [
        "### Questions — Part 2\n",
        "\n",
        "We want to use this model for long-time MD simulations of Li ion diffusion in LiPS. How can we tell if it's accurate enough?\n",
        "\n",
        "- Which do we think is more important for this task; energy or force accuracy? Why?\n",
        "- How do the train/val/test MAE/RMSEs compare? Does this give us some indications about overfitting? Based on these metrics, do we think the model is sufficiently accurate?\n",
        "  - What about the difference in MAE to RMSE? Does this give us some insight about our data/error distribution?\n",
        "- Typical required force accuracies for ion diffusion MD simulations are ~,50 meV/Å – how does our model compare?\n",
        "- What are some strategies we could use to further validate the performance of our model (and its predictions in MD simulations)?\n",
        "- What could we do to improve our model accuracy?\n",
        "- What would happen if we trained on fewer configurations (e.g., 100 instead of 1000)? What about more (e.g., 5000)?\n",
        "- What is the effect of the cutoff radius `r_max`? How would increasing it affect accuracy and computational cost? What about other model hyperparameters?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd4f358",
      "metadata": {
        "id": "2fd4f358"
      },
      "source": [
        "---\n",
        "# Part 3: Molecular Dynamics Simulations\n",
        "\n",
        "Now that we have a trained MLIP (i.e. energy & forces calculator), we can use it to run molecular dynamics —\n",
        "propagating the atomic positions and velocities as a function of time, using classical Newtonian mechanics to generate a trajectory.\n",
        "\n",
        "### Key MD concepts:\n",
        "\n",
        "- **Timestep**: Typically should be small enough to resolve the fastest vibrations. For systems with light atoms like Hydrogen, in our lectures we said 0.5–1 fs is typical. What is the lightest atom in our system here, and what timestep do we think we should use?\n",
        "  - Remember for deciding our timestep; too little and the simulation is inefficient, too large and we will get integration errors and unstable dynamics.\n",
        "- **MD Ensemble**: The set of thermodynamic variables held constant during the simulation. We will use the same ensemble as the reference data here – was it NVT or NPT?\n",
        "- **Equilibration**: The initial part of the MD simulation where the system relaxes from the starting configuration to thermal equilibrium. We discard this data.\n",
        "- **Production**: The part of the MD simulation *after* equilibration, from which we extract physical properties.\n",
        "\n",
        "### Our plan:\n",
        "We will run a demonstration MD simulation at 800 K. At elevated temperatures, Li ions\n",
        "diffuse faster, making it easier to observe diffusion on accessible MD timescales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94fd9a2f",
      "metadata": {
        "id": "94fd9a2f"
      },
      "source": [
        "### 3.1 Setting Up the Simulation\n",
        "\n",
        "To start, we will use the same simulation cell as the training data, taking a random configuration from the dataset as our starting structure.\n",
        "We will initialise atomic velocities from a Maxwell-Boltzmann distribution, corresponding to our simulation temperature of 800 K."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a552ac",
      "metadata": {
        "id": "27a552ac"
      },
      "outputs": [],
      "source": [
        "# here we define a function to run a simple MD simulation, which uses functions from the ASE package:\n",
        "from ase import units\n",
        "from ase.md.langevin import Langevin\n",
        "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
        "\n",
        "import random\n",
        "import os\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "\n",
        "def simpleMD(atoms_init, temp, calc, output_fname, timestep, num_steps):\n",
        "    # set our calculator:\n",
        "    atoms_init.set_calculator(calc)\n",
        "\n",
        "    # initialize the temperature\n",
        "    random.seed(701)  # (this is just to make the MD simulation fully reproducible)\n",
        "    MaxwellBoltzmannDistribution(atoms_init, temperature_K=temp)  # initialize temperature at `temp`\n",
        "\n",
        "    # set up our MD dynamics; here we use a 'Langevin' thermostat,\n",
        "    # which is a simple way to control the temperature of the system.\n",
        "    # we also set the timestep here\n",
        "    dyn = Langevin(atoms_init, timestep*units.fs, temperature_K=temp, friction=0.1)\n",
        "    # see here: https://ase-lib.org/ase/md.html\n",
        "\n",
        "    # here we add some code to monitor the temperature and energy of the system as\n",
        "    # a function of time in the MD simulation:\n",
        "    time_fs = []\n",
        "    temperature = []\n",
        "    energies = []\n",
        "\n",
        "    os.system('rm -rfv '+output_fname)  # remove any previously stored trajectory with the same name\n",
        "    fig, ax = pl.subplots(2, 1, figsize=(6,6), sharex='all', gridspec_kw={'hspace': 0, 'wspace': 0}, dpi=500)  # generates dynamic plot as MD proceeds\n",
        "\n",
        "    def write_frame():  # this is a function we add to the MD dynamics to monitor the system\n",
        "        dyn.atoms.write(output_fname, append=True)  # store current frame in output trajectory file\n",
        "        time_fs.append(dyn.get_time()/units.fs)  # store the current time in fs\n",
        "        temperature.append(dyn.atoms.get_temperature())  # store the current temperature\n",
        "        energies.append(dyn.atoms.get_potential_energy()/len(dyn.atoms))  # store the current energy\n",
        "\n",
        "        # plot the energy of the system as a function of time\n",
        "        ax[0].plot(np.array(time_fs), np.array(energies), color=\"b\")\n",
        "        ax[0].set_ylabel('E (eV/atom)')\n",
        "\n",
        "        # plot the temperature of the system as a function of time\n",
        "        ax[1].plot(np.array(time_fs), temperature, color=\"r\")\n",
        "        ax[1].set_ylabel('T (K)')\n",
        "        ax[1].set_xlabel('Time (fs)')\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(pl.gcf())\n",
        "\n",
        "    dyn.attach(write_frame)  # adds our writing & plotting function to the MD calculation\n",
        "    dyn.run(num_steps)  # runs our MD calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "092dc22b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "092dc22b",
        "outputId": "2d360608-e4f3-4479-a82d-91930232c315"
      },
      "outputs": [],
      "source": [
        "# let's run MD with this function:\n",
        "atoms_init = dataset[1447].copy()\n",
        "temp = 550  # in K\n",
        "timestep = 20  # timestep in fs\n",
        "num_steps = 500  # max number of steps\n",
        "output_fname = 'MD_550K.xyz'  # output trajectory file\n",
        "\n",
        "simpleMD(atoms_init, temp, calc, output_fname, timestep, num_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d39cb8",
      "metadata": {
        "id": "25d39cb8"
      },
      "source": [
        "By monitoring the temperature and energy, we can see if the simulation is proceeding as expected, and when our equilibration phase has completed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "807f3224",
      "metadata": {
        "id": "807f3224"
      },
      "source": [
        "- Is this MD simulation running ok? Why / why not?\n",
        "    - No, timestep too big, it's exploding!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce932552",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ce932552",
        "outputId": "674bd1d8-088e-4c3d-c89e-214db1d944c7"
      },
      "outputs": [],
      "source": [
        "# let's run MD with this function:\n",
        "atoms_init = dataset[1447].copy()\n",
        "temp = 550  # in K\n",
        "timestep = 1  # timestep in fs\n",
        "num_steps = 500  # 5000 steps\n",
        "output_fname = 'MD_550K.xyz'  # output trajectory file\n",
        "\n",
        "simpleMD(atoms_init, temp, calc, output_fname, timestep, num_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pp6AZXRqHE8v",
      "metadata": {
        "id": "pp6AZXRqHE8v"
      },
      "source": [
        "Our temperature, which is the average kinetic energy of the system, is still varying somewhat here. What could we do to reduce these fluctuations a bit more?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n2pB47tCHsKr",
      "metadata": {
        "id": "n2pB47tCHsKr"
      },
      "source": [
        "A typical rule of thumb is that for a well-equilibrated NVT simulation, the temperature variation $\\Delta T$ should be approximately equal to $T \\times \\sqrt{2/f}$ where $f = 3N$ is the number of degrees of freedom in the system, with $N$ being the number of particles (atoms). How does our temperature variation here compare to this expectation?​"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aTf8wU9oJRpW",
      "metadata": {
        "id": "aTf8wU9oJRpW"
      },
      "source": [
        "When we use a MLIP as our energy/forces calculator in MD, we know that there are still some (hopefully small) remnant errors in the energy/forces prediction at each timestep. In short, this means that the energy surface of our calculator is not as 'smooth'. This means that the MD simulation becomes more sensitive to potential sources of numerical errors – what might we want to change as a result, to ensure stable MLIP-accelerated MD simulations?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37a3acb6",
      "metadata": {},
      "source": [
        "- When does the equilibration phase complete? How can we tell?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "195bd59a",
      "metadata": {
        "id": "195bd59a"
      },
      "source": [
        "### 3.2 Visualising the Trajectory\n",
        "\n",
        "We can load the saved trajectory and visualise it, using the same tools we used earlier to visualise the training data. You should be able to see the Li\n",
        "ions moving through the PS₄ framework — this is ionic diffusion in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374f4073",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "374f4073",
        "outputId": "e78d3cb6-30d3-4d88-85ee-4b3d2a04357e"
      },
      "outputs": [],
      "source": [
        "# Load our MD trajectory data (from `output_fname` in the simpleMD function above)\n",
        "# we can do this using the same code we used earlier to read data from the xyz format:\n",
        "from ase.io import read\n",
        "traj = read(\"MD_550K.xyz\", index=\":\")\n",
        "print(f\"Loaded {len(traj)} trajectory frames\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6b7f89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "0f6b7f89",
        "outputId": "583bf1a2-738f-476d-d5ab-8bba0a8cb2df"
      },
      "outputs": [],
      "source": [
        "from ase.visualize.plot import plot_atoms\n",
        "\n",
        "# let's generate images of a few snapshots from our trajectory:\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "# this selects the 100th, 200th, 300th, 400th frames from the trajectory for plotting\n",
        "for i, idx in enumerate([100, 200, 300, 400]):  # snapshots at 1,2,3,4 ps\n",
        "    plot_atoms(traj[idx], axes[i], rotation=\"10x,10y,0z\")\n",
        "    axes[i].set_title(f\"t ≈ {idx/1000:.0f} ps\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Trajectory snapshots at 500 K\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4619d2f",
      "metadata": {
        "id": "b4619d2f"
      },
      "source": [
        "Using the `TrajectoryWidget` tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7b23222",
      "metadata": {
        "id": "d7b23222"
      },
      "outputs": [],
      "source": [
        "widgets.TrajectoryWidget(traj)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j1vSzJzwMWU3",
      "metadata": {
        "id": "j1vSzJzwMWU3"
      },
      "source": [
        "**RDF Analysis:**\n",
        "\n",
        "Let's look at the Radial Distribution Function (RDF) of the atoms in our MD simulation. As we briefly discussed in our lectures, the RDF gives a quantitative description of the connectivity of atoms in our material, giving the average distances between atoms of different element pairs.\n",
        "\n",
        "To do this, we can use the `Analysis` class from ASE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IDtKh--2MvUt",
      "metadata": {
        "id": "IDtKh--2MvUt"
      },
      "outputs": [],
      "source": [
        "from ase.geometry.analysis import Analysis\n",
        "\n",
        "analysis = Analysis(traj)\n",
        "rdf_per_timestep = analysis.get_rdf(rmax=5, nbins = 25)  # specify radial cutoff for RDF, and num histogram bins from 0 to `rmax`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WL92DFHoNCI0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "WL92DFHoNCI0",
        "outputId": "29de737a-2f67-4409-f16a-4c9825c3922f"
      },
      "outputs": [],
      "source": [
        "# Plot the average RDF:\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "r_bins = np.linspace(0, 5, 25)  # from 0 to rmax, with nbins intervals\n",
        "\n",
        "# this rdf data includes all timesteps, so remove the equilibration period and only include the production stage:\n",
        "production_stage_rdf_per_timestep = rdf_per_timestep[250:]  # only from 250th timestep on\n",
        "\n",
        "# get average RDF over this time period:\n",
        "production_stage_average_rdf = np.mean(production_stage_rdf_per_timestep, axis=0)\n",
        "\n",
        "# plot\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "ax.plot(r_bins, production_stage_average_rdf, color=\"steelblue\")\n",
        "ax.set_xlabel(r\"Distance $r$ ($\\mathrm{\\AA}$)\")\n",
        "ax.set_ylabel(\"Average Radial Distribution Function (RDF)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4DlqKUnpPh_-",
      "metadata": {
        "id": "4DlqKUnpPh_-"
      },
      "source": [
        "This plot is a bit jagged. Why? How can we get a smoother plot here?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VR9BOjtBQsbG",
      "metadata": {
        "id": "VR9BOjtBQsbG"
      },
      "source": [
        "This is the total (non-element-specific) RDF for all atoms in the simulation here. Now let's plot the RDF for some specific elemental pairs; namely Li-Li, P-S and Li-S:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0Xzm0Z2BPnXA",
      "metadata": {
        "id": "0Xzm0Z2BPnXA"
      },
      "outputs": [],
      "source": [
        "# get Li-Li, P-S and Li-S RDFs, and plot separately\n",
        "\n",
        "Li_Li_rdf_per_timestep = analysis.get_rdf(rmax=5, nbins = 200, elements=['Li'])\n",
        "P_S_rdf_per_timestep = analysis.get_rdf(rmax=5, nbins = 200, elements=['P', 'S'])\n",
        "Li_S_rdf_per_timestep = analysis.get_rdf(rmax=5, nbins = 200, elements=['Li', 'S'])\n",
        "r_bins = np.linspace(0, 5, 200)\n",
        "\n",
        "Li_Li_production_stage_average_rdf = np.mean(Li_Li_rdf_per_timestep[200:], axis=0)\n",
        "P_S_production_stage_average_rdf = np.mean(P_S_rdf_per_timestep[200:], axis=0)\n",
        "Li_S_production_stage_average_rdf = np.mean(Li_S_rdf_per_timestep[200:], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iik_ycL8REzK",
      "metadata": {
        "id": "iik_ycL8REzK"
      },
      "source": [
        "Now let's plot these RDFs all alongside:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2hHNWv6UPm13",
      "metadata": {
        "id": "2hHNWv6UPm13"
      },
      "outputs": [],
      "source": [
        "f,ax = plt.subplots(figsize=(7,5))\n",
        "ax.plot(r_bins, Li_Li_production_stage_average_rdf, color=\"steelblue\", label=\"Li-Li\")\n",
        "ax.plot(r_bins, P_S_production_stage_average_rdf, color=\"green\", label=\"P-S\")\n",
        "ax.plot(r_bins, Li_S_production_stage_average_rdf, color=\"purple\", label=\"Li-S\")\n",
        "ax.set_xlabel(r\"Distance $r$ ($\\mathrm{\\AA}$)\")\n",
        "ax.set_ylabel(\"Average Radial Distribution Function (RDF)\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9849e075",
      "metadata": {
        "id": "9849e075"
      },
      "source": [
        "### Questions — Part 3\n",
        "- From our visualisations, which atoms are moving the most in the simulation? Does this match our expectations? Why?\n",
        "- How do we know if the simulation has properly equilibrated?\n",
        "- What would happen if you used a timestep of 25 fs instead of 1 fs? Why?\n",
        "- From the RDFs how crystalline/disordered/liquid-like is our material (and specific element pairings) in this simulation? Does this match our expectations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dbd318c",
      "metadata": {
        "id": "6dbd318c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a93e63c0",
      "metadata": {
        "id": "a93e63c0"
      },
      "source": [
        "---\n",
        "# Part 4: Extracting the Diffusion Coefficient\n",
        "\n",
        "As very briefly mentioned in lectures, the **mean squared displacement (MSD)** quantifies how far atoms have moved from\n",
        "their initial positions, averaged over all atoms of that type:\n",
        "\n",
        "$$\\text{MSD}(\\Delta t) = \\left\\langle \\frac{1}{N_{\\text{Li}}} \\sum_{i=1}^{N_{\\text{Li}}} |\\mathbf{r}_i(\\Delta t) - \\mathbf{r}_i(t=0)|^2 \\right\\rangle_{\\Delta t}$$\n",
        "\n",
        "Where $\\Delta t$ is the time change, $N_{\\text{Li}}$ is the number of Li atoms and $\\mathbf{r}_i(\\Delta t)$ is the position of the $i$th Li atom at time $\\Delta t$.\n",
        "\n",
        "For a diffusing species in 3D, the MSD grows linearly with time according to:\n",
        "\n",
        "$$\\text{MSD}(\\Delta t) = 6D\\Delta t$$\n",
        "\n",
        "where $D$ is the **self-diffusion coefficient**. The factor of 6 comes from the three\n",
        "spatial dimensions (2 per dimension)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac4d8654",
      "metadata": {
        "id": "ac4d8654"
      },
      "source": [
        "We can use the `DiffusionCoefficient` class from ASE to directly compute the diffusion coefficient from the trajectory -- this is a nice example of the benefits of the computational materials science ecosystem! Complex analysis code has already been written for us, so we just need to feed in the right data to proceed with our material simulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f860ad",
      "metadata": {
        "id": "e9f860ad"
      },
      "outputs": [],
      "source": [
        "from ase.md.analysis import DiffusionCoefficient\n",
        "\n",
        "msd_calc = DiffusionCoefficient(\n",
        "    traj,  # trajectory over which to compute the diffusion coefficient\n",
        "    timestep=1.0,  # timestep used with this trajectory\n",
        "    atom_indices=list(range(27))  # atomic indices for which to compute diffusion coefficients (the first 27 atoms are Li, in our Li27P12S44 cell)\n",
        ")  \n",
        "msd_calc.calculate()  # run the Diffusion Coefficient calculation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33Dd_BvxSKFv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "33Dd_BvxSKFv",
        "outputId": "d29ee7b7-99dd-4da0-aee4-d70c62f39ea9"
      },
      "outputs": [],
      "source": [
        "msd_calc.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JzJVd9mwTD99",
      "metadata": {
        "id": "JzJVd9mwTD99"
      },
      "source": [
        "Something is a bit inaccurate with how we have performed extracted the diffusion coefficient from our MD trajectory here – what? Let's fix it and re-run the diffusion coefficient analysis.\n",
        "\n",
        "We used the whole trajectory for the diffusion analysis, but should only use the production stage!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b12f9edb",
      "metadata": {
        "id": "b12f9edb",
        "outputId": "518803c7-be84-4a73-ab9c-da5e5de12fd1"
      },
      "outputs": [],
      "source": [
        "from ase.md.analysis import DiffusionCoefficient\n",
        "\n",
        "msd_calc = DiffusionCoefficient(\n",
        "    # this selects only the 250th timestep onwards of the trajectory (i.e. the production stage)\n",
        "    traj[250:],  # trajectory over which to compute the diffusion coefficient\n",
        "    timestep=1.0,  # timestep used with this trajectory\n",
        "    atom_indices=list(range(27))  # atomic indices for which to compute diffusion coefficients (the first 27 atoms are Li, in our Li27P12S44 cell)\n",
        ")  \n",
        "msd_calc.calculate()  # run the Diffusion Coefficient calculation\n",
        "\n",
        "msd_calc.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ad879c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ad879c5",
        "outputId": "e27ea958-6eb7-4e0e-c7bd-3f9078c7a2e9"
      },
      "outputs": [],
      "source": [
        "# we can then get the fitted diffusion coefficient from the linear fit with this function:\n",
        "D_array, std_dev_array = msd_calc.get_diffusion_coefficients()\n",
        "D = D_array[0]*units.fs  # units are Å^2/fs\n",
        "D_cm2s = D * 0.1  # Å^2/fs = 0.1 cm^2/s\n",
        "std_dev = std_dev_array[0]*units.fs  # units are Å^2/fs\n",
        "std_dev_cm2s = std_dev * 0.1  # Å^2/fs = 0.1 cm^2/s\n",
        "print(f\"Linear fit diffusion coefficient: {D_cm2s:.2e} (+/- {std_dev_cm2s:.0e}) cm²/s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sQyDKwqzUiMx",
      "metadata": {
        "id": "sQyDKwqzUiMx"
      },
      "source": [
        "### Questions — Part 4\n",
        "\n",
        "- Does the MSD show a clear linear regime? Why/why not? What does this tell us about the stability/convergence of our simulation?\n",
        "  - Is it more ballistic ($\\propto t^2$) or diffusive ($\\propto t$) behaviour?\n",
        "- How sensitive is the extracted $D$ to the choice of fitting range?\n",
        "\n",
        "- Why do we only compute the MSD for Li atoms and not for P or S?\n",
        "\n",
        "- How does our extracted diffusion coefficient $D$ compare to typical diffusion coefficients? (Based on Googling and quickly searching the literature (Elicit, SciSpace and Consensus are some popular LLM literature search tools...))\n",
        "\n",
        "- What about for (defective) Li solid-state electrolytes, under our specific simulation conditions?\n",
        "\n",
        "- Would the  increase or decrease with the simulation temperature?\n",
        "\n",
        "- Do we have enough data to get a good fit for our diffusion coefficient here? How does our standard deviation of the fit compare to the extracted value for the diffusion coefficient?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lD04IS1FVqrd",
      "metadata": {
        "id": "lD04IS1FVqrd"
      },
      "source": [
        "**Not in class notebook:**\n",
        "- Experimental measurements for Li₇P₃S₁₁ get $D \\sim 10^{-8}$–$10^{-7}$ cm²/s at room temperature. How does our value of $D$ differ and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FFuoGOcWXSV7",
      "metadata": {
        "id": "FFuoGOcWXSV7"
      },
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "In this practical you have:\n",
        "\n",
        "1. **Explored** a DFT dataset for a (defective) Li₇P₃S₁₁ solid electrolyte\n",
        "2. **Trained** a MACE machine-learning interatomic potential on DFT configurations\n",
        "3. **Ran** molecular dynamics simulations of this solid electrolyte\n",
        "4. **Extracted** the Li-ion self-diffusion coefficient from mean squared displacement analysis\n",
        "\n",
        "### The big picture\n",
        "\n",
        "This workflow — DFT → MLIP → MD → transport properties — is now a standard tool in\n",
        "computational materials science. The same approach can be applied to simulations of:\n",
        "- Other solid electrolytes (garnet, perovskite, NASICON-type stryctures)\n",
        "- Electrode materials (lithium intercalation kinetics)\n",
        "- Thermal conductivity\n",
        "- Phase transitions and structural dynamics\n",
        "- ...\n",
        "\n",
        "Here we have seen that Li-ion diffusion is indeed very fast in this system, corroborating the fact that it is a promising candidate for a solid-state electrolyte for advanced Li-ion batteries!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N4cTv4hwZdRY",
      "metadata": {
        "id": "N4cTv4hwZdRY"
      },
      "source": [
        "**Reminder:**\n",
        "\n",
        "In this practical there are a number of technical and discussion/conceptual questions. It is recommended that you record answers as you go, and download the completed notebook at the end of the practical session, to use as a resource for reference with the practical report and follow-on task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2e4ec19",
      "metadata": {
        "id": "f2e4ec19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9006b4a3",
      "metadata": {
        "id": "9006b4a3"
      },
      "source": [
        "---\n",
        "# Part 5: Determining the Activation Energy\n",
        "\n",
        "Li-ion diffusion is a thermally activated process which can described by the **Arrhenius relation**:\n",
        "\n",
        "$$D(T) = D_0 \\exp\\left(-\\frac{E_a}{k_B T}\\right)$$\n",
        "\n",
        "where:\n",
        "- $D_0$ is the pre-exponential factor\n",
        "- $E_a$ is the **activation energy** (the barrier for Li-ion hopping)\n",
        "- $k_B$ is Boltzmann's constant\n",
        "- $T$ is the temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7NAQFysMWJLY",
      "metadata": {
        "id": "7NAQFysMWJLY"
      },
      "source": [
        "How can we use this relation and our ability to compute $D$ with MD to determine the activation energy?\n",
        "\n",
        "Do this, determining $D_0$, $E_a$ for Li-ion diffusion in this system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa3913e8",
      "metadata": {},
      "source": [
        "Here are some cells to run which setup our data, so we don't need to re-run the whole notebook above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d289ee8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# this automatically downloads our data, so we don't need to manually download and upload\n",
        "# as we did in the practical session:\n",
        "!git clone https://github.com/SAM-Laboratory/AMET_Comp_Practical\n",
        "%cd AMET_Comp_Practical\n",
        "!gzip -d LiPS.xyz.gz  # decompress the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d77e5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages:\n",
        "!pip install mace-torch ase matplotlib numpy scipy pymatviz pymatgen\n",
        "!pip install cuequivariance_torch  # this speeds up our model training (accelerated tensor products)\n",
        "# Make sure Runtime -> Change runtime type -> GPU is selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff73baab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import standard scientific Python packages; numpy, matplotlib:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\")  # ignore irrelevant warnings for this practical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e084751",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset, which is stored in XYZ format (.xyz)\n",
        "# Each frame contains: atomic positions, forces, total energy, and the simulation cell\n",
        "from ase.io import read\n",
        "\n",
        "print(\"Loading DFT dataset...\")\n",
        "dataset = read(\"LiPS.xyz\", index=\":\")  # read all frames in the dataset\n",
        "print(f\"Loaded {len(dataset)} configurations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb3acd34",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ase.io import write\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# first, subsample 10% of the dataset\n",
        "subsampled_dataset = dataset[::10]  # this takes every 10th frame in the dataset\n",
        "\n",
        "# First split off train from test/val; with 80/20 split\n",
        "train_set, test_val_set = train_test_split(subsampled_dataset, train_size=0.8, test_size=0.2)\n",
        "\n",
        "# split test/val into val and test; with 50/50 split (corresponding to 10/10 split overall)\n",
        "test_set, val_set = train_test_split(test_val_set, test_size=0.5, train_size=0.5)\n",
        "\n",
        "# Save split datasets to files for MLIP training\n",
        "write(\"LiPS_train.xyz\", train_set)\n",
        "write(\"LiPS_val.xyz\", val_set)\n",
        "write(\"LiPS_test.xyz\", test_set)\n",
        "\n",
        "print(f\"Training set:   {len(train_set)} configurations\")\n",
        "print(f\"Validation set: {len(val_set)} configurations\")\n",
        "print(f\"Test set:       {len(test_set)} configurations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec36c758",
      "metadata": {},
      "outputs": [],
      "source": [
        "# here we define a function to run a simple MD simulation, which uses functions from the ASE package:\n",
        "from ase import units\n",
        "from ase.md.langevin import Langevin\n",
        "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
        "\n",
        "import random\n",
        "import os\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "\n",
        "def simpleMD(atoms_init, temp, calc, output_fname, timestep, num_steps):\n",
        "    # set our calculator:\n",
        "    atoms_init.set_calculator(calc)\n",
        "\n",
        "    # initialize the temperature\n",
        "    random.seed(701)  # (this is just to make the MD simulation fully reproducible)\n",
        "    MaxwellBoltzmannDistribution(atoms_init, temperature_K=temp)  # initialize temperature at `temp`\n",
        "\n",
        "    # set up our MD dynamics; here we use a 'Langevin' thermostat,\n",
        "    # which is a simple way to control the temperature of the system.\n",
        "    # we also set the timestep here\n",
        "    dyn = Langevin(atoms_init, timestep*units.fs, temperature_K=temp, friction=0.1)\n",
        "    # see here: https://ase-lib.org/ase/md.html\n",
        "\n",
        "    # here we add some code to monitor the temperature and energy of the system as\n",
        "    # a function of time in the MD simulation:\n",
        "    time_fs = []\n",
        "    temperature = []\n",
        "    energies = []\n",
        "\n",
        "    os.system('rm -rfv '+output_fname)  # remove any previously stored trajectory with the same name\n",
        "    fig, ax = pl.subplots(2, 1, figsize=(6,6), sharex='all', gridspec_kw={'hspace': 0, 'wspace': 0}, dpi=500)  # generates dynamic plot as MD proceeds\n",
        "\n",
        "    def write_frame():  # this is a function we add to the MD dynamics to monitor the system\n",
        "        dyn.atoms.write(output_fname, append=True)  # store current frame in output trajectory file\n",
        "        time_fs.append(dyn.get_time()/units.fs)  # store the current time in fs\n",
        "        temperature.append(dyn.atoms.get_temperature())  # store the current temperature\n",
        "        energies.append(dyn.atoms.get_potential_energy()/len(dyn.atoms))  # store the current energy\n",
        "\n",
        "        # plot the energy of the system as a function of time\n",
        "        ax[0].plot(np.array(time_fs), np.array(energies), color=\"b\")\n",
        "        ax[0].set_ylabel('E (eV/atom)')\n",
        "\n",
        "        # plot the temperature of the system as a function of time\n",
        "        ax[1].plot(np.array(time_fs), temperature, color=\"r\")\n",
        "        ax[1].set_ylabel('T (K)')\n",
        "        ax[1].set_xlabel('Time (fs)')\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(pl.gcf())\n",
        "\n",
        "    dyn.attach(write_frame)  # adds our writing & plotting function to the MD calculation\n",
        "    dyn.run(num_steps)  # runs our MD calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb7254c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be41c8bd",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6f878633",
      "metadata": {
        "id": "6f878633"
      },
      "source": [
        "### Questions — Part 5\n",
        "\n",
        "- How well converged are the $D_0$ and $E_a$ values here?\n",
        "- Are the $D_0$ and $E_a$ values temperature-dependent? Why / why not?\n",
        "- Does the Arrhenius plot show a clear linear relationship? Why / why not, and what does this imply about the diffusion mechanism?\n",
        "- How does your activation energy of Li-ion diffusion compare to values in the literature for (non-defective) Li₇P₃S₁₁? If it differs, what are possible reasons?\n",
        "- Would you trust the diffusion coefficient extracted at a very low temperature (e.g. 50 K) here? Why or why not?\n",
        "- How would you improve the accuracy of the activation energy determination?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a023cfff",
      "metadata": {
        "id": "a023cfff"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fc619ded",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 6: Learning Curves\n",
        "\n",
        "A common and very useful task in MLIP training is to generate and consider 'learning curves', which plot the accuracy of the MLIP as a function of some parameter; typically either the size of the training dataset, the number of training epochs, or the number of parameters in the model.\n",
        "\n",
        "This can give useful information about the model 'scaling' – i.e. how we can expect the accuracy of the model to improve with more data, more training, or more parameters.\n",
        "\n",
        "Generate a learning curve for the MACE model here, with dataset size as our variable parameter, using datasets of every 1000th, 100th, 50th, 10th, 5th, 2nd and every frame in the AIMD dataset, as the dataset sizes to test – in the example below we take every 10th frame. For each, you will need to record the **_test_** RMSE and MAE of the model for energies and forces, to then plot against dataset size to generate the learning curve.\n",
        "\n",
        "For model training here, you can reduce the number of training epochs to 20 to speed up the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b108ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# earlier we used this code to take every 10th frame from the raw AIMD dataset, to then\n",
        "# generate training, validation and test sets:\n",
        "from ase.io import write\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# this takes every 10th frame in the dataset; we can modify this to generate datasets\n",
        "# of different sizes, and then train MACE models (with the same model settings, for consistency)\n",
        "# on these different datasets to generate learning curves:\n",
        "subsampled_dataset = dataset[::10]  # this takes every 10th frame in the dataset\n",
        "\n",
        "# First split off train from test/val; with 80/20 split\n",
        "train_set, test_val_set = train_test_split(subsampled_dataset, train_size=0.8, test_size=0.2)\n",
        "\n",
        "# split test/val into val and test; with 50/50 split (corresponding to 10/10 split overall)\n",
        "test_set, val_set = train_test_split(test_val_set, test_size=0.5, train_size=0.5)\n",
        "\n",
        "# Save split datasets to files for MLIP training\n",
        "write(\"LiPS_train.xyz\", train_set)\n",
        "write(\"LiPS_val.xyz\", val_set)\n",
        "write(\"LiPS_test.xyz\", test_set)\n",
        "\n",
        "print(f\"Training set:   {len(train_set)} configurations\")\n",
        "print(f\"Validation set: {len(val_set)} configurations\")\n",
        "print(f\"Test set:       {len(test_set)} configurations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ec59ddd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# model training for different dataset sizes..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2683e12e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# example code for plotting learning curves:\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 25001 is the number of frames in the AIMD dataset, so dataset sizes are 25001/[interval between frames extracted for training]\n",
        "dataset_sizes = 25001/np.array([1000, 100, 50, 10, 5, 2, 1])  \n",
        "\n",
        "per_atom_energy_MAEs = [7, 6, 5, 4, 3, 2, 1]  # example MAE values for different dataset sizes\n",
        "per_atom_energy_RMSEs = [10, 8, 6, 4, 2, 1, 0.5]  # example RMSE values for different dataset sizes\n",
        "\n",
        "force_MAEs = [0.05, 0.04, 0.03, 0.02, 0.01, 0.005, 0.001]  # example MAE values for different dataset sizes\n",
        "force_RMSEs = [0.1, 0.08, 0.06, 0.04, 0.02, 0.01, 0.005]  # example RMSE values for different dataset sizes\n",
        "\n",
        "# plot the learning curves:\n",
        "f,ax = plt.subplots(figsize=(7,5))\n",
        "ax.plot(dataset_sizes, per_atom_energy_MAEs, color=\"steelblue\", label=\"Energy MAE\")\n",
        "ax.plot(dataset_sizes, per_atom_energy_RMSEs, color=\"steelblue\", label=\"Energy RMSE\")\n",
        "ax.plot(dataset_sizes, force_MAEs, color=\"green\", label=\"Force MAE\")\n",
        "ax.plot(dataset_sizes, force_RMSEs, color=\"green\", label=\"Force RMSE\")\n",
        "ax.set_xlabel(\"Dataset Size\")\n",
        "ax.set_ylabel(\"MAE\")\n",
        "ax.legend()\n",
        "# ax.set_xscale(\"log\")  # uncomment these to see log-log plot, usually best!\n",
        "# ax.set_yscale(\"log\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c08a9c79",
      "metadata": {},
      "source": [
        "- What relationship do we find between the MAE/RMSEs and dataset size? (Linear, parabolic, exponential, logarithmic, etc.)\n",
        "- What dataset size (assuming the same data origin, sampling technique and model settings as above) would we need to achieve:\n",
        "    - Energy MAE < 10 meV/atom? <1 meV/atom? <0.1 meV/atom?\n",
        "    - Force MAE < 50 meV/Å? <1 meV/Å?\n",
        "    - Energy RMSE < 10 meV/atom? <0.1 meV/atom?\n",
        "    - Force RMSE < 100 meV/Å? <10 meV/Å?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28120ae6",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "af92df95",
      "metadata": {},
      "source": [
        "We can similarly generate a learning curve with _model size_ as our variable parameter, by varying the number of parameters in the model through the settings in our config file.\n",
        "\n",
        "Generate such a learning curve, by varying the model hyperparameters in the config file and recording the MAE/RMSEs and the total number of model parameters (printed in the MACE training output log).\n",
        "I recommend varying `num_channels`, `max_L`, and `max_ell` for this, but you can also vary other hyper-parameters too if you are feeling adventurous. Either way, you should aim for at least 5-6 datapoints (of different model sizes) to plot for the learning curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e4f2646",
      "metadata": {},
      "outputs": [],
      "source": [
        "# example code for plotting learning curves:\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# total parameter counts of the models tested\n",
        "model_sizes = [100000, 50000, 25000, 10000, 5000, 2500, 1000]\n",
        "\n",
        "per_atom_energy_MAEs = [7, 6, 5, 4, 3, 2, 1]  # example MAE values for different model sizes\n",
        "per_atom_energy_RMSEs = [10, 8, 6, 4, 2, 1, 0.5]  # example RMSE values for different model sizes\n",
        "\n",
        "force_MAEs = [0.05, 0.04, 0.03, 0.02, 0.01, 0.005, 0.001]  # example MAE values for different model sizes\n",
        "force_RMSEs = [0.1, 0.08, 0.06, 0.04, 0.02, 0.01, 0.005]  # example RMSE values for different model sizes\n",
        "\n",
        "# plot the learning curves:\n",
        "f,ax = plt.subplots(figsize=(7,5))\n",
        "ax.plot(model_sizes, per_atom_energy_MAEs, color=\"steelblue\", label=\"Energy MAE\")\n",
        "ax.plot(model_sizes, per_atom_energy_RMSEs, color=\"steelblue\", label=\"Energy RMSE\")\n",
        "ax.plot(model_sizes, force_MAEs, color=\"green\", label=\"Force MAE\")\n",
        "ax.plot(model_sizes, force_RMSEs, color=\"green\", label=\"Force RMSE\")\n",
        "ax.set_xlabel(\"Model Size\")\n",
        "ax.set_ylabel(\"MAE\")\n",
        "ax.legend()\n",
        "# ax.set_xscale(\"log\")  # uncomment these to see log-log plot, usually best!\n",
        "# ax.set_yscale(\"log\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31f43364",
      "metadata": {},
      "source": [
        "- Is the scaling behaviour here similar to the dataset size learning curve, or not? Why?\n",
        "- What happens to the time required to train (and evaluate) the model as we increase the model size?\n",
        "- Why don't we just use the model settings which give us the most accurate model possible? (Thinking in terms of both training and production simulations)\n",
        "- Roughly what model size do we need to achieve:\n",
        "    - a force MAE < 10 meV/Å?\n",
        "    - an energy MAE < 1 meV/atom?\n",
        "    - a force RMSE < 10 meV/Å?\n",
        "    - an energy RMSE < 0.1 meV/atom?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9266c5b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "535ce8ca",
      "metadata": {},
      "source": [
        "### Re-Evaluating the RDF and Diffusion Coefficient $D$\n",
        "\n",
        "Re-compute the RDF and diffusion coefficient $D$ with one of the more accurate models obtained from the learning curves above (you will need to factor in evaluation speeds for this choice), with the goal of maximising the accuracy of these predicted properties.\n",
        "\n",
        "- Explain your choice of model/dataset size for this evaluation.\n",
        "- How do these values compare to the values obtained from that in the practical session? Is this reasonable? Which values would you trust more?\n",
        "    - What does this tell us about the sensitivities of these particular properties to the accuracy of our underlying MD calculator?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09507cd8",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d16f91f2",
      "metadata": {},
      "source": [
        "### Data Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e078bce3",
      "metadata": {},
      "source": [
        "Re-do the dataset-size learning curve, but instead of our interval-based sampling (of taking each n-th frame from the AIMD data), lets just take the first $n$ frames from the AIMD data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5a9004c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example code for taking the first n frames from the AIMD data:\n",
        "from ase.io import write\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# this takes the first 500 frames in the dataset; we can modify this to generate datasets\n",
        "# of different sizes, and then train MACE models (with the same model settings, for consistency)\n",
        "# on these different datasets to generate learning curves:\n",
        "subsampled_dataset = dataset[:500]  # this takes the first 500 frames in the dataset\n",
        "\n",
        "# First split off train from test/val; with 80/20 split\n",
        "train_set, test_val_set = train_test_split(subsampled_dataset, train_size=0.8, test_size=0.2)\n",
        "\n",
        "# split test/val into val and test; with 50/50 split (corresponding to 10/10 split overall)\n",
        "test_set, val_set = train_test_split(test_val_set, test_size=0.5, train_size=0.5)\n",
        "\n",
        "# Save split datasets to files for MLIP training\n",
        "write(\"LiPS_train.xyz\", train_set)\n",
        "write(\"LiPS_val.xyz\", val_set)\n",
        "write(\"LiPS_test.xyz\", test_set)\n",
        "\n",
        "print(f\"Training set:   {len(train_set)} configurations\")\n",
        "print(f\"Validation set: {len(val_set)} configurations\")\n",
        "print(f\"Test set:       {len(test_set)} configurations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52d1490f",
      "metadata": {},
      "source": [
        "- How does the learning curve change? Why? (think back to our lectures!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95128670",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3a198a64",
      "metadata": {},
      "source": [
        "As we revealed from our data analyses in the practical session, our training data here comes from a ab-initio MD simulations (i.e. MD with DFT as the calculator). \n",
        "\n",
        "- If we want to increase our dataset size to improve the accuracy of our trained MLIPs for this system, but for the minimal compute cost (i.e. minimum number of DFT calculations), what would be some possible strategies?\n",
        "\n",
        "- What is the advantage/limitation of just running more AIMD simulations to extend the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db4d566",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a684d81",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e356924b",
      "metadata": {
        "id": "e356924b"
      },
      "source": [
        "### Notes on improving the MACE model:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc839748",
      "metadata": {
        "id": "bc839748"
      },
      "source": [
        "MACE has different hyper parameters that controls the degree of accuracy and expressivity of the model. Setting these parameters is a trade off between accuracy and computational cost. Most MACE parameters have robust and well tested defaults. We call them here \"Parameters to keep to default values\" but mention them for general knowledge. The \"Hyper Parameters to Change\" are hyper parameters that need to be adjusted as they can be task or system dependent.\n",
        "\n",
        "### Hyper Parameters to Change:\n",
        "\n",
        "- **`--num_channels`: Number of channels**\n",
        "  \n",
        "  Determines the size of the model. The recommended value is `--num_channels=128` but other potential values are `64` for a faster model or `256` for a large but more accurate model.\n",
        "  \n",
        "  \n",
        "- **`max_L`: Symmetry of the messages**\n",
        "\n",
        "  Determines the symmetry of the messages. A value of `--max_L=0` means MACE will pass only invariant information between neigborhoods. It is the parameter **that affects the most the computational speed and the accuracy of the model**. `--max_L=0` are the fastest model, use them to train cheap model to run large and long simulations. `--max_L=1` is the default value, it is a good compromise between speed and accuracy. It is recommended to start with that value for a new project. `--max_L=2` are the most accurate models, use them to train very accurate but slower models.\n",
        "  \n",
        "\n",
        "- **`--r_max`: The cutoff radius**\n",
        "  \n",
        "  The cutoff used to create the local environment in each layer. `r_max=5.0` means atoms separated by a distance of more than 5.0 Å do not directly communicate in a single layer. When the model has multiple message-passing layers, atoms further than 5.0 Å can still communicate through later messages if intermediate proxy atoms exist. The effective receptive field of the model is `num_interactions * r_max`. The larger the `r_max`, the slower the model will be. It is recommended to use values between 4.0 Å and 7.0 Å.\n",
        "\n",
        "---\n",
        "\n",
        "### Hyper Parameters to keep to default values (for general knowledge):\n",
        "\n",
        "- **`--num_interactions`: Message-passing layers**\n",
        "  \n",
        "  Controls the number of message-passing layers in the model. It should always be 2, and it is recommended not to modify it.\n",
        "\n",
        "\n",
        "- **`--correlation`: The order of the many-body expansion**\n",
        "\n",
        "  The body order that MACE induces at each layer. Choosing `--correlation=3` will create basis functions of up to 4-body (ijkl) indices, for each layer. If the model has multiple layers, the effective correlation order is higher. For example, a two-layer MACE with `--correlation=3` has an effective body order of 13.\n",
        "\n",
        "\n",
        "- **`--max_ell`: Angular resolution**\n",
        "\n",
        "  The angular resolution describes how well the model can describe angles. This is controlled by `max_ell` of the spherical harmonics basis (not to be confused with `max_L`). Larger values will result in more accurate but slower models. The default is `max_ell=3`, which is appropriate in most cases.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
